<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis">
    <meta name="author" content="Eric Chan,
                                 Marco Monteiro,
                                 Other Authors">

    <title>pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap" rel="stylesheet">
    <!-- <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@100;200&display=swap" rel="stylesheet"> -->

    <!-- Custom styles for this template -->

    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->

    <!-- Loads <model-viewer> for modern browsers: -->
    <script type="module"
            src="https://unpkg.com/@google/model-viewer/dist/model-viewer.js">
    </script>

    <!-- <link href="offcanvas.css" rel="stylesheet" type="text/css" media="screen"> -->
    <link href="main.css" rel="stylesheet" type="text/css">

</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>pi-GAN: Periodic Implicit Generative Adversarial Networks</h2>
    <h2>for 3D-Aware Image Synthesis</h2>
    <hr>
    <p class="authors">
        <a href="https://ericryanchan.github.io/"> Eric Chan*</a>,
        <a href="">Marco Monteiro*</a>,</br>
        <a href="https://kellnhofer.xyz/">Petr Kellnhofer</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://stanford.edu/~gordonwz/"> Gordon Wetzstein</a>,</br>
        Stanford University </br>
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary"
           href="pdf/compressed_paper.pdf">Compressed Paper</a>
        <a class="btn btn-primary"
           href="https://arxiv.org/pdf/2012.00926.pdf">Arxiv Paper</a>
        <a class="btn btn-primary disabled" href="">Code</a>
        <a class="btn btn-primary disabled" href="">Data</a>
    </div>
</div>

<div class="container">
    <div class="section">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <!-- <video width="80%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/pi-GAN.mp4" type="video/mp4">
                </video> -->
                <iframe width="720" height="405" src="https://www.youtube.com/embed/0HCdof9BGtw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </div>
        <hr>
        <p>
            We have witnessed rapid progress on 3D-aware image synthesis,
            leveraging recent advances in generative visual models and neural
            rendering. Existing approaches however fall short in two ways:
            first, they may lack an underlying 3D representation or rely on
            view-inconsistent rendering, hence synthesizing images that are
            not multi-view consistent; second, they often depend upon
            representation network architectures that are not expressive
            enough, and their results thus lack in image quality. We propose
            a novel generative model, named Periodic Implicit Generative
            Adversarial Networks (π-GAN or pi-GAN), for high-quality 3D-aware
            image synthesis. π-GAN leverages neural representations with
            periodic activation functions and volumetric rendering to represent
            scenes as view-consistent 3D representations with fine detail.
            The proposed approach obtains state-of-the-art results for 3D-aware
            image synthesis with multiple real and synthetic datasets.
        </p>
    </div>

    <div class="section">
        <h2>Results</h2>
        <hr>
        <p>
            π-GAN leverages recent advances in generative visual models
            and neural rendering to produce high-quality, multi-view-consistent
            images.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="vids/results.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <p>
            π-GAN achieves state-of-the-art results for 3D aware image synthesis on CelebA, 
            Cats, and CARLA. Below we show a comparison between HoloGAN, GRAF, and π-GAN.
        </p>

        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="vids/fast_comparison.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Interpreting the 3D Representation</h2>
        <hr>
        <p>
            pi-GAN relies on an underlying multi-view-consistent 3D representation.
            We can interpret the 3D represenation as a mesh through marching
            cubes on the density output of the conditioned radiance
            field.

        <!-- </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="80%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/asdf.mp4" type="video/mp4">
                </video>
            </div>
        </div> -->

        <div class="container">
                    <div class="row align-items-center">
                        <div class="col-sm padding-0 canvas-row">
                            <video width="200px" playsinline="" autoplay="" loop="" preload="" muted="">
                                <source src="vids/face_3d_reconstruction.mp4" type="video/mp4">
                            </video>
                        </div>

                        <div class="col-sm padding-0 canvas-row">
                            <model-viewer
                                    alt="Ground Truth"
                                    src="glbs/face.glb"
                                    style="width: 200px; height: 200px; background-color: #FFFFFF"
                                    exposure=".8"
                                    camera-orbit="0deg 75deg 105%"
                                    auto-rotate
                                    camera-controls>
                            </model-viewer>
                        </div>


                        <div class="col-sm padding-0 canvas-row">
                            <video width="200px" playsinline="" autoplay="" loop="" preload="" muted="">
                                <source src="vids/car_3d_reconstruction.mp4" type="video/mp4">
                            </video>
                        </div>

                        <div class="col-sm padding-0 canvas-row">
                            <model-viewer
                                    alt="DeepSDF"
                                    src="glbs/car.glb"
                                    style="width: 200px; height: 200px; background-color: #FFFFFF"
                                    exposure=".8"
                                    auto-rotate
                                    camera-controls>
                            </model-viewer>
                            <!--                            poster="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5e7e6db2d75a9b467eee4111_legomesh_cover.png"-->
                        </div>
                    </div>
          </div>

    </div>

    <div class="section">
        <h2>Inverse Rendering and Novel View Synthesis</h2>
        <hr>
        <p>
            Using a trained π-GAN generator, we can perform single-view reconstruction
            and novel-view synthesis. After freezing the parameters of our implicit
            representation, we optimize for the conditioning parameters that produce a
            radiance field which, when rendered, best matches the target image.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="40%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="vids/inverse_render.mp4" type="video/mp4">
                </video>
            </div>
        </div>

    </div>

    <div class="section">
        <h2>π-GAN Extrapolates to Unseen Camera Poses</h2>
        <hr>
        <p>
            The underling 3D structural representation makes π-GAN more capable
            of rendering views absent from the training distribution of camera
            poses than previous methods that lacked 3D representations or relied
            on black-box neural rendering. π-GAN offers explicit control
            over position, rotation, focal length, and other camera parameters.
            Despite training only on closely cropped images of Cats, π-GAN
            can render images at much higher or much lower magnification.

        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="30%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="vids/extrapolation.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </div>








    <div class="section">
        <h2>Arxiv</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/pdf/2012.00926.pdf"
                   class="list-group-item">
                    <img src="img/paper_thumbnails.png" style="width:100%; margin-right:-20px">
                </a>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @inproceedings{chanmonteiro2020pi-GAN,
                author = {Chan, Eric
                          and Monteiro, Marco
                          and Kellnhofer, Petr
                          and Wu, Jiajun
                          and Wetzstein, Gordon},
                title = {pi-GAN: Periodic Implicit Generative Adversarial
                  Networks for 3D-Aware Image Synthesis},
                booktitle = {arXiv},
                year={2020}
            }
        </div>
    </div>

    <hr>
    <p style="margin-top: 30px;">We would like to offer special thanks to Matthew Chan for fruitful discussions and assistance in completing this work. We'd like to thank Stanford HAI for the AWS Cloud Credits. Gordon Wetzstein was supported by an NSF CAREER Award (IIS 1553333), a Sloan Fellowship, and a PECASE from the ARO.</p>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
